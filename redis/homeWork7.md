Цель:
В результате выполнения ДЗ вы поработаете с Redis.

Описание/Пошаговая инструкция выполнения домашнего задания:
Необходимо:

сохранить большой жсон (~20МБ) в виде разных структур - строка, hset, zset, list;
протестировать скорость сохранения и чтения;
предоставить отчет.
Задание повышенной сложности*
настроить редис кластер на 3х нодах с отказоусточивостью, затюнить таймоуты



Домашнее задание часть 1.

Нашел на просторах интернета большой json
Поднял отдельный redis с конфигфайлом из лекции, с помощью docker compose (прилагается, соседний файл)
Уменьшил в конфигфайле время для логирования запроса 
slowlog-log-slower-than 10
Пользовался командой SLOWLOG get для оценки времени выполнения


1) Запись и чтение в виде  строки

выполнил вставку из файла с помощью:
cat /Users/d.rutkovskii/study/redis/test-data/large-file.json | redis-cli -x SET my-large-json:string

SLOWLOG GET 
   3) (integer) 18
   4) 1) "SET"
      2) "my-large-json:string"
      3) "[{\"id\":\"2489651045\",\"type\":\"CreateEvent\",\"actor\":{\"id\":665991,\"login\":\"petroav\",\"gravatar_id\":\"\",\"url\":\"https://api.github.com/u... (26141215 more bytes)"


Получил значение из ключа:
get my-large-json:string
    
3) (integer) 7710
   4) 1) "get"
      2) "my-large-json:string"


2) Запись и чтение в виде хэш таблицы
Для записи использовал скрипт python (прилагается, соседний файл)

 3) (integer) 14 (колеблется)
    4) 1) "HSET"
       2) "user:2489677732"
       3) "payload"
       4) "{\"action\": \"closed\", \"number\": 36, \"pull_request\": {\"url\": \"https://api.github.com/repos/robokurssi-joulu14/massive-ironman/pull... (15819 more bytes)"

Т.о. т.к. редис работает в 1 потоке, не смотря на транзакцию, предоплагаю что для каждого элемента каждой хэш таблицы время выполения условно 14 микросекунд.
Соответственно 14 микросек * 5 элементов в одноуровневой хэш-таблице * 11351 всего = 794570мксек




3) Запись и чтение в виде упорядоченного множества
Для записи использовал скрипт python (прилагается, соседний файл)
Время записи 1 элемена в множество
 3) (integer) 16 (колеблется)
    4) 1) "ZADD"
       2) "user"
       3) "10990"
       4) "{\"id\": \"2489678042\", \"type\": \"PullRequestReviewCommentEvent\", \"actor\": {\"id\": 4823572, \"login\": \"sandlerben\", \"gravatar_id\": \"\",... (18910 more bytes)"
Итого общее время записи (примерно) в виде zet 16 * 11351 = 181616мксек

Не нашел команды чтобы получить все хэштаблицы, поэтому предполагаю оценку времени получения как выполенние команды
HGETALL user:{uid} * кол-во элеменов 
3) (integer) 16
    4) 1) "HGETALL"
       2) "user:2489678336"

       итого 16 * 11351 = 181616

Чтение всего множества командой 
zrange user 0 -1
  3) (integer) 16503
    4) 1) "zrange"
       2) "user"
       3) "0"
       4) "-1"




4) Запись и чтение list
Для записи использовал скрипт python (прилагается, соседний файл)
Время записи 1 элемена в лист.
3) (integer) 25 (Колеблется)
    4) 1) "RPUSH"
       2) "users"
       3) "{\"id\": \"2489677992\", \"type\": \"IssuesEvent\", \"actor\": {\"id\": 6762977, \"login\": \"KeanePW\", \"gravatar_id\": \"\", \"url\": \"https://api.... (57770 more bytes)"
Количество элементов: 
LLEN users 11351
Итого общее время записи (примерно) в виде list  11351 * 25 = 283755 микросекунд


Чтение всего списка командой 
LRANGE users 0 -1
3) (integer) 33350
    4) 1) "LRANGE"
       2) "users"
       3) "0"
       4) "-1"



Вывод: быстрей всего (но менее функциональней) записать весь большой json в виде строки в redis


Часть 2 (задание под звездочкой)
